import re
import json

from scrapy.selector import Selector
from scrapy.selector import HtmlXPathSelector
try:
    from scrapy.spider import Spider
except:
    from scrapy.spider import BaseSpider as Spider
from scrapy.utils.response import get_base_url
from scrapy.utils.response import get_base_url
from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor as sle
from scrapy.contrib.linkextractors import LinkExtractor
from scrapy.http import Request
from babaSR.items import BabaSRItem

class EngadgetSpider(CrawlSpider):
    name = "babaSR"
    allowed_domains = ["engadget.com"]
    start_urls = [
        "http://cn.engadget.com/topics/wearables/",
        # "http://cn.engadget.com/topics/gps/",
        # "http://cn.engadget.com/topics/household/",
        # "http://cn.engadget.com/topics/pmp/",
        # "http://cn.engadget.com/topics/fitness/"
    ]
    # rules = [
    #     Rule(sle(allow=("/subject/\d+/?$")), callback='parse_2'),
    #     Rule(sle(allow=("/tag/[^/]+/?$", )), follow=True),
    #     Rule(sle(allow=("/tag/$", )), follow=True),
    # ]
    # 
    def parseContent(self,article):
        article = article[0].encode('utf-8')
        #print chardet.detect(content)
        #print 'article:',article
        var1 = '<div class="copy post-body " itemprop="text">'
        contentIndex =article.index(var1)
        content = article[11:contentIndex-2]
        nameIndex = article.index('<div role="nav" id="header-post-nav" class="postnav">')
        name = article[nameIndex+8:contentIndex-2]
        pictureIndex = article.index('<img')
        picture = article[pictureIndex+26:pictureIndex+50]
        price = 0.0
        paylink = None
        setting = None
        tag = None
        return (name,picture,content,price,paylink,setting,tag)

    def parse_item(self,response):
        hxs =Selector(response)
        productitem = response.meta['item']
        productitems = []
        article = hxs.xpath('//*[@id="body"]').extract()
        # parseContent detail method
        parseTuple = self.parseContent(article)
        productitem['name'] = parseTuple[0].decode('utf-8')
        productitem['picture'] =parseTuple[1].decode('utf-8')
        productitem['content'] = parseTuple[2]
        productitem['price'] = parseTuple[3]
        productitem['paylink'] = parseTuple[4]
        productitem['setting'] = parseTuple[5]
        productitem['tag'] = parseTuple[6]
        #item['desc'] = parseTuple[7]
        productitems.append(productitem)
        return productitems
    
    # main parse method in Spider
    def parse(self, response):
        hxs = Selector(response)  
        newurls = hxs.xpath('//article/a/@href').extract()
        validurls = []  
        for url in newurls:   
            if 'http' not in url:
                url = 'http://store.baidu.com' + url
            validurls.append(url)  
            print 'validurl:',url
                
        items = [] 
        items.extend([self.make_requests_from_url(url).replace(callback=self.parse) for url in validurls])  
        print 'items:',items

        sites = hxs.xpath('//ul/li')
        items = []
        for site in sites:
            item = BabaSRItem()
            item['title'] = site.xpath('a/text()').extract()
            item['link'] = site.xpath('a/@href').extract()
            items.append(item)
            print 'itemInfo:',item
            yield Request(item['link'],meta={'item':item},callback=self.parse_item)
        
        #return items  
